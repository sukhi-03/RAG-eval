{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa8ykQk92aLX"
      },
      "source": [
        "# Evaluation with RAGAS and Advanced Retrieval Methods Using LangChain\n",
        "\n",
        "In the following notebook we'll discuss a major component of LLM Ops:\n",
        "\n",
        "- Evaluation\n",
        "\n",
        "We're going to be leveraging the [RAGAS]() framework for our evaluations today as it's becoming a standard method of evaluating (at least directionally) RAG systems.\n",
        "\n",
        "We're also going to discuss a few more powerful Retrieval Systems that can potentially improve the quality of our generations!\n",
        "\n",
        "Let's start as we always do: Grabbing our dependencies!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5BN13TZlSCv4"
      },
      "outputs": [],
      "source": [
        "# !pip install -U -q langchain openai ragas arxiv pymupdf chromadb wandb tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Lhqp5rUThG-",
        "outputId": "c33f7eee-b819-40bd-dc75-ce90721a6a94"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/asura/miniconda3/envs/qdoc/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/tmp/ipykernel_42910/4238627262.py:23: DeprecationWarning: The 'timeout' parameter is deprecated in favor of 'request_timeout'\n",
            "  elastic_search_client=Elasticsearch(cloud_id=es_cloud_id, api_key=es_api_key, timeout=300)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import openai\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from werkzeug.utils import secure_filename\n",
        "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
        "from langchain.schema import Document\n",
        "from elasticsearch import Elasticsearch\n",
        "from langchain_elasticsearch import ElasticsearchStore\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import logging\n",
        "from langchain_community.vectorstores.faiss import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import OllamaEmbeddings\n",
        "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
        "\n",
        "\n",
        "\n",
        "es_cloud_id=\"id\"\n",
        "es_api_key=\"key\"\n",
        "elastic_search_client=Elasticsearch(cloud_id=es_cloud_id, api_key=es_api_key, timeout=300)\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'key'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTDNFXaBSO2j",
        "outputId": "3b24521d-5c6f-466b-d818-46ce68d359ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/asura/miniconda3/envs/qdoc/lib/python3.12/site-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from this module in 48.0.0.\n",
            "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#loader\n",
        "loader = PyPDFLoader(\"diary.pdf\")\n",
        "docs = loader.load()\n",
        "len(docs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNPAWPgNSyGP",
        "outputId": "b2f80fc8-792c-489a-b8d4-9f98678c679a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'source': 'diary.pdf', 'page': 0}\n",
            "{'source': 'diary.pdf', 'page': 1}\n",
            "{'source': 'diary.pdf', 'page': 2}\n",
            "{'source': 'diary.pdf', 'page': 3}\n",
            "{'source': 'diary.pdf', 'page': 4}\n",
            "{'source': 'diary.pdf', 'page': 5}\n",
            "{'source': 'diary.pdf', 'page': 6}\n",
            "{'source': 'diary.pdf', 'page': 7}\n",
            "{'source': 'diary.pdf', 'page': 8}\n",
            "{'source': 'diary.pdf', 'page': 9}\n",
            "{'source': 'diary.pdf', 'page': 10}\n",
            "{'source': 'diary.pdf', 'page': 11}\n",
            "{'source': 'diary.pdf', 'page': 12}\n",
            "{'source': 'diary.pdf', 'page': 13}\n",
            "{'source': 'diary.pdf', 'page': 14}\n",
            "{'source': 'diary.pdf', 'page': 15}\n",
            "{'source': 'diary.pdf', 'page': 16}\n",
            "{'source': 'diary.pdf', 'page': 17}\n",
            "{'source': 'diary.pdf', 'page': 18}\n",
            "{'source': 'diary.pdf', 'page': 19}\n",
            "{'source': 'diary.pdf', 'page': 20}\n"
          ]
        }
      ],
      "source": [
        "for doc in docs:\n",
        "  print(doc.metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ht6bJX9PAY"
      },
      "source": [
        "### Creating an Index\n",
        "\n",
        "Let's use a naive index creation strategy of just using `RecursiveCharacterTextSplitter` on our documents and embedding each into our `VectorStore` using `OpenAIEmbeddings()`.\n",
        "\n",
        "- [`RecursiveCharacterTextSplitter()`](https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.RecursiveCharacterTextSplitter.html)\n",
        "- [`Chroma`](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.chroma.Chroma.html?highlight=chroma#langchain.vectorstores.chroma.Chroma)\n",
        "- [`OpenAIEmbeddings()`](https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.openai.OpenAIEmbeddings.html?highlight=openaiembeddings#langchain-embeddings-openai-openaiembeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xne8P5dQTUiR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1722939386.148771   42910 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def get_hierarchical_chunks(pages):\n",
        "    headers_to_split_on = [\n",
        "        (\"#\", \"Header 1\"),\n",
        "        (\"##\", \"Header 2\"),\n",
        "        (\"###\", \"Header 3\"),\n",
        "    ]\n",
        "    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
        "    \n",
        "    final_chunks = []\n",
        "    for page in pages:\n",
        "        md_header_splits = markdown_splitter.split_text(page.page_content)\n",
        "        \n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=2000,\n",
        "            chunk_overlap=400,\n",
        "            length_function=len,\n",
        "            separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        "        )\n",
        "\n",
        "        for doc in md_header_splits:\n",
        "            smaller_chunks = text_splitter.split_text(doc.page_content)\n",
        "            for chunk in smaller_chunks:\n",
        "                final_chunks.append(Document(\n",
        "                    page_content=chunk,\n",
        "                    metadata={\n",
        "                        \"source\": page.metadata.get(\"source\", \"\"),\n",
        "                        \"page\": page.metadata.get(\"page\", \"\"),\n",
        "                        \"header\": \" > \".join([doc.metadata.get(f\"Header {i}\", \"\") for i in range(1, 4) if f\"Header {i}\" in doc.metadata])\n",
        "                    }\n",
        "                ))\n",
        "\n",
        "    return final_chunks\n",
        "\n",
        "def get_text_chunks(pages, user_session):\n",
        "    # Assuming `pages` is a list of Document objects, each representing a page of the document\n",
        "    all_chunks = []\n",
        "\n",
        "    # Iterate over each page and apply hierarchical chunking\n",
        "    full_text = \"\"\n",
        "    for page in pages:\n",
        "        # Get hierarchical chunks\n",
        "        hierarchical_chunks = get_hierarchical_chunks([page])\n",
        "        all_chunks.extend(hierarchical_chunks)\n",
        "        full_text += page.page_content\n",
        "    \n",
        "    if not os.path.exists(user_session):\n",
        "        os.makedirs(user_session)\n",
        "    filename = f'{user_session}/content.txt'\n",
        "    with open(filename, \"w\") as file:\n",
        "        file.write(full_text)\n",
        "    \n",
        "    return all_chunks\n",
        "\n",
        "docss = get_text_chunks(docs, 'surya')\n",
        "\n",
        "def elastic_store(docs, user_session):\n",
        "    db = ElasticsearchStore.from_documents(\n",
        "    docs,\n",
        "    es_cloud_id=\"1964ec43953b4c07957e65d979ba0958:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvJGM1ZTk5M2RjYzIzZTQ5Mzg4NGQzYzY3Zjk5NzczODY5JGY4MjQ4NTI3MDE4YzQ5NmI4MTcwMmEzMGZiM2E3MmUz\",\n",
        "        index_name=user_session,\n",
        "            es_api_key=\"U0VtaTlKQUJFM3llVzNOT1VrZ2M6T1ZteHR4WUZSRWV0RkxyVFJ5TXNFQQ==\"\n",
        "                )\n",
        "    db.client.indices.refresh(index=user_session)\n",
        "\n",
        "def get_vector_store(text_chunks, usersession):\n",
        "    try:\n",
        "        logging.info('creating vector store')\n",
        "        #embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
        "        embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "        logging.info('embedding model chosen')\n",
        "        vector_store = FAISS.from_documents(text_chunks, embedding=embeddings)\n",
        "        logging.info(f'faiss vector created')\n",
        "        vector_store.save_local(usersession)\n",
        "        logging.info(f'FAISS index stored to local: {usersession}')\n",
        "    except Exception as e:\n",
        "        logging.info(e)\n",
        "        raise\n",
        "\n",
        "def store_vector(raw_text, user_session):\n",
        "    text_chunks = get_text_chunks(raw_text, user_session)\n",
        "    logging.info('text converted to chunks')\n",
        "    # Store to FAISS index\n",
        "    get_vector_store(text_chunks, user_session)\n",
        "\n",
        "    # Store Elastic Search index\n",
        "    if elastic_search_client.indices.exists(index=user_session):\n",
        "        elastic_search_client.indices.delete(index=user_session)\n",
        "        logging.info(f\"Index '{user_session}' deleted.\")\n",
        "    elastic_search_client.indices.create(index=user_session)\n",
        "    logging.info(f\"Index '{user_session}' created successfully.\")\n",
        "    elastic_store(text_chunks, user_session)\n",
        "    logging.info(\"Chunks stored to Elastic Search\")\n",
        "\n",
        " \n",
        "\n",
        "store_vector(docss, 'surya')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnRzYx4c_2mZ",
        "outputId": "59d9bdd8-0414-4e8b-c285-bf3a2760e26a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyUh8EVI_6TZ",
        "outputId": "643fca9d-77c0-4296-d953-ec62d6de8954"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1998\n"
          ]
        }
      ],
      "source": [
        "print(max([len(chunk.page_content) for chunk in docss]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f9kNIUUTxdT"
      },
      "source": [
        "Let's convert our `Chroma` vectorstore into a retriever with the `.as_retriever()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_elasticsearch.retrievers import ElasticsearchRetriever\n",
        "from langchain.retrievers import EnsembleRetriever\n",
        "from elasticsearch import Elasticsearch\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.chat_models import ChatOllama \n",
        "from langchain_community.embeddings import OllamaEmbeddings\n",
        "from langchain_community.vectorstores.faiss import FAISS\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "import json\n",
        "import requests\n",
        "import logging\n",
        "import time\n",
        "from langchain_google_genai.chat_models import ChatGoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dynamic_body_func(query):\n",
        "    return {\n",
        "        \"size\": 1,\n",
        "        \"query\": {\n",
        "            \"match\": {\n",
        "                \"content\": query\n",
        "            }\n",
        "        },\n",
        "        \"_source\": {\n",
        "            \"includes\": [\"content\"]\n",
        "        }\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bwbdftltT29h"
      },
      "outputs": [],
      "source": [
        "es_weight = 0.6\n",
        "faiss_weight = 0.4\n",
        "weights = [es_weight,faiss_weight]\n",
        "llm = ChatOllama(model=\"llama3.1\")\n",
        "client=Elasticsearch(cloud_id=\"1964ec43953b4c07957e65d979ba0958:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvJGM1ZTk5M2RjYzIzZTQ5Mzg4NGQzYzY3Zjk5NzczODY5JGY4MjQ4NTI3MDE4YzQ5NmI4MTcwMmEzMGZiM2E3MmUz\",api_key=\"U0VtaTlKQUJFM3llVzNOT1VrZ2M6T1ZteHR4WUZSRWV0RkxyVFJ5TXNFQQ==\")\n",
        "esret = ElasticsearchRetriever(es_client=client,body_func=dynamic_body_func,  es_cloud_id=\"1964ec43953b4c07957e65d979ba0958:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvJGM1ZTk5M2RjYzIzZTQ5Mzg4NGQzYzY3Zjk5NzczODY5JGY4MjQ4NTI3MDE4YzQ5NmI4MTcwMmEzMGZiM2E3MmUz\", index_name='surya', es_api_key=\"U0VtaTlKQUJFM3llVzNOT1VrZ2M6T1ZteHR4WUZSRWV0RkxyVFJ5TXNFQQ==\", content_field=\"content\")\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "new_db = FAISS.load_local('surya', embeddings, allow_dangerous_deserialization=True).as_retriever()\n",
        "base_retriever = ensemble_retriever = EnsembleRetriever(retrievers=[esret, new_db], weights=weights)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBPZQUt4UBPl"
      },
      "source": [
        "Now to give it a test!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "r0Pie4xqUCkW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/asura/miniconda3/envs/qdoc/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "relevant_docs = base_retriever.get_relevant_documents('tell me about Westertoren clock')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_CiHTD0UKj7",
        "outputId": "fab040cf-971f-440a-a6aa-93873c8e152f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(relevant_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8MKsT6JTgCU"
      },
      "source": [
        "## Creating a Retrieval Augmented Generation Prompt\n",
        "\n",
        "Now we can set up a prompt template that will be used to provide the LLM with the necessary contexts, user query, and instructions!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ijSNkTAjTsep"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = prompt_template = \"\"\"\n",
        "Answer the question as detailed as possible but only on the provided context.  Review the chat history carefully to provide all necessary details and avoid incorrect information. Treat synonyms or similar words as equivalent within the context. For example, if a question refers to \"modules\" or \"units\" instead of \"chapters\" or \"doc\" instead of \"document\" consider them the same. \n",
        "If the question is not related to the provided context, simply respond that the question is out of context and instead provide a summary of the document and example questions that the user can ask.\n",
        "Do not make up an answer if the provided question is not within the context. Instead, provide example questions that the user can ask and summary of the document.\n",
        "Do not repeat facts in the answer if you have already stated them. \n",
        "If the question is short, like it is asking for the dates, names or requires a very short answer then keep the response short and to the point. \n",
        "If the question asks for a particular keyword that is in context, state information related to that keyword. \n",
        "Example: Question : When was bill gates born?\n",
        "Answer: According to the documents you have uploaded, bill gates was born in 1989. \n",
        "However, if the question requires a detailed answer, then consider all possibiliies related to the question and try to answer in Bullet points and clear and concise paragraphs. \n",
        "If asked to summarise the document, try to provide a basic summary of the entire context and cover it in bullet points but keep the answer concise and not too long. \n",
        "If the question mention 'what are the contents of the file' or asks about the uploaded document or anything similar, just cover the entire document as a summary.\n",
        "VERY IMPORTANT State the source in the end along with the answer but dont state the source if the question is out of context.\n",
        "If the source is like : temp/abc.docx, then just mention the file name like abc.docx.\n",
        "In the beginning of the anser, always mention the exact line in quotation marks that is being referred to in the answer and enclose it within **bold** tags.\n",
        "Example : \"According to the document in the line \"The company was started in 1990\", to answer your question(state the query in a shorter and concise manner), the company was founded in 1990.\"\n",
        "Highlight Key Points: Enclose each identified key point within `**bold**` tags.\n",
        "Highlight Keywords: Enclose each identified keyword within `*italic*` tags.\n",
        "Documents:\\n{context}\\n\n",
        "Question:\\n{question}\\n\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYHnPaXl-cvJ"
      },
      "source": [
        "### Setting Up our Basic QA Chain\n",
        "\n",
        "Now we can instantiate our basic RAG chain!\n",
        "\n",
        "We'll follow *exactly* the chain we made on Tuesday to keep things simple for now - if you need a refresher on what it looked like - check out last week's notebook!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-TsjUWjbUfbW"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
        "\n",
        "model = ChatOllama(temperature=0.2, model=\"llama3.1\", top_p=0.5, top_k=10)\n",
        "\n",
        "retrieval_augmented_qa_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | base_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": prompt | model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO69de-F-oMD"
      },
      "source": [
        "Let's test it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FS5NxC6UyU2",
        "outputId": "2520bf73-9e62-435c-a213-c26d0655a913"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'response': AIMessage(content='', response_metadata={'model': 'llama3.1', 'created_at': '2024-08-06T10:18:50.846549926Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 125940596792, 'load_duration': 1288213482, 'prompt_eval_count': 1026, 'prompt_eval_duration': 124560063000, 'eval_count': 1, 'eval_duration': 27000}, id='run-86fc5c29-5419-48d2-a150-fec25dd54a05-0'), 'context': [Document(metadata={'source': 'diary.pdf', 'page': 4, 'header': ''}, page_content='hadn’t eaten a hot meal all day, but we didn’t care; Mother and Margot were too\\ntired and keyed up to eat, and Father and I were too busy.\\nTuesday morning we started where we left off the night before. Bep and Miep\\nwentgrocery shopping with our ration coupons, Father worked on our blackout\\nscreens, we scrubbed the kitchen floor, and were once again busy from sunup to\\nsundown. Until Wednesday, I didn’t have a chance to think about the enormous\\nchange in my life.\\nThen for the first time since our arrival in the Secret Annex, I found a moment\\nto tell you all about it and to realize what had happened to me and what was yet to\\nhappen.\\nYours, Anne\\nDearest Kitty,\\nFather, Mother and Margot still can’t get used to the chiming of the\\nWestertoren clock, which tells us the time every quarter of an hour. Not me, I liked it\\nfrom the start; it sounds so reassuring, especially at night. You no doubt want to\\nhear what I think of being in hiding. Well, all I can say is that I don’t really know yet.\\nI don’t think I’ll ever feel at home in this house, but that doesn’t mean I hate it. It’s\\nmore like being on vacation in some strange pension. Kind of an odd way to look at\\nlife in hiding, but that’s how things are. The Annex is an ideal place to hide in. It may\\nbe damp and lopsided, but there’s probably not a more comfortable hiding place in\\nall of Amsterdam. Not in all of Holland.Saturday, July 11, 1942\\nUp to now our bedroom, with its blank walls, was very bare. Thanks to\\nFather - who brought my entire postcard and movie-star collection here\\n23'), Document(metadata={'source': 'diary.pdf', 'page': 5, 'header': ''}, page_content='beforehand - and to a brush and a pot of glue, I was able to plaster the walls with\\npictures. It looks much more cheerful. When the van Daans arrive, we’ll be able\\nto build cupboards and other odds and ends out of the wood piled in the attic.\\nMargot and Mother have recovered somewhat. Yesterday Mother felt well\\nenough to cook split-pea soup for the first time, but then she was down stairs\\ntalking and forgot all about it. The beans were scorched black, and no amount of\\nscraping could get them out of the pan.\\nLast night the four of us went down to the private office and listened to\\nEngland on the radio. I was so scared someone might hear it that I literally\\nbegged Father to take me back upstairs. Mother understood my anxiety and\\nwent with me. Whatever we do, we’re very afraid the neighbors might hear or\\nsee us. We started off immediately the first day sewing curtains. Actually, you\\ncan hardly call them that, since they’re nothing but scraps of fabric, varying\\ngreatly in shape, quality and pattern, which Father and Istitched crookedly\\ntogether with unskilled fingers. These works of art were tacked tothe windows,\\nwhere they’ll stay until we come out of hiding.\\nThe building on our right is a branch of the Keg Company, a firm from\\nZaandam, andon the left is a furniture workshop. Though the people who work\\nthere are not on the premises after hours, any sound we make might travel\\nthrough the walls. We’ve forbidden Margot to cough at night, even though she\\nhas a bad cold, and are giving her large doses of codeine.\\nI’m looking forward to the arrival of the van Daans, which is set for\\nTuesday. It will be much more fun and also not as quiet. You see, it’s the silence\\nthat makes me so nervous during the evenings and nights, and I’d give anything\\nto have one of our helpers sleep here.\\nIt’s really not that bad here, since we can do our own cooking and can listen\\nto the radio in Daddy’s office.\\nMr. Kleiman and Miep, and Bep Voskuijl too, have helped us so much. We’ve'), Document(metadata={'source': 'diary.pdf', 'page': 7, 'header': ''}, page_content='with my age. I’d like to spend all my time writing, but that would probably get\\nboring. Up to now I’ve only confided my thoughts to my diary. I still haven’t\\ngotten around to writing amusing sketches that I could read aloud at a later date.\\nIn the future I’m going to devote less time to sentimentality and more time to\\nreality.\\nDear Kitty,\\nI’ve deserted you for an entire month, but so little has happened that I can’t\\nfind a news worthy item to relate every single day. The van Daans arrived on\\nJuly 13. We thought they were coming on the fourteenth, but from the thirteenth\\nto sixteenth the Germans were sending out call-up notices right and left and\\ncausing a lot of unrest, so they decided it would be safer to leave a day too early\\nthan a day too late.\\nPeter van Daan arrived at nine-thirty in the morning (while we were still at\\nbreakfast). Peter’s going on sixteen, a shy, awkward boy whose company won’t\\namount too much. Mr. and Mrs. van Daan came half an hour later. Much to our\\namusement, Mrs. van Daan was carrying a hatbox with a large chamber pot\\ninside. “I just don’t feel at home without my chamber pot,” she exclaimed, and it\\nwas the first item to find a permanent place under the divan. Instead of a\\nchamber pot, Mr. van D. was lugging a collapsible tea table under his arm.\\nFrom the first, we ate our meals together, and after three days it felt as if the\\nseven of us had become one big family. Naturally, the van Daans had much to\\ntell about the week we’d been away from civilization. We were especially\\ninterested in what had happened to our apartment and to Mr. Goldschmidt.Friday, August 14, 1942\\n26'), Document(metadata={'source': 'diary.pdf', 'page': 10, 'header': ''}, page_content='to normal.\\nYours, Anne\\nDearest Kitty,\\nToday I’ll tell you the general news here in the Annex. A lamp has been\\nmounted above my divan bed so that in the future, when I hear the guns going\\noff, I’ll be able to pull a cord and switch on the light. I can’t use it at the moment\\nbecause we’re keeping our window open a little, day and night.\\nThe male members of the van Daan contingent have built a very handy\\nwood-stainedfood safe, with real screens. Up to now this glorious cupboard has\\nbeen located in Peter’s room, but in the interests of fresh air it’s been moved to\\nthe attic. Where it once stood, there’s now a shelf. I advised Peter to put his table Monday, September 21, 1942\\n29')]}\n"
          ]
        }
      ],
      "source": [
        "question = \"tell me about Westertoren clock.\"\n",
        "\n",
        "result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyazkAIu85KL"
      },
      "source": [
        "### Ground Truth Dataset Creation Using GPT-3.5-turbo and GPT-4\n",
        "\n",
        "The next section might take you a long time to run, so the evaluation dataset is provided.\n",
        "\n",
        "The basic idea is that we can use LangChain to create questions based on our contexts, and then answer those questions.\n",
        "\n",
        "Let's look at how that works in the code!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V24T_gpPatAO"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers import ResponseSchema\n",
        "from langchain.output_parsers import StructuredOutputParser\n",
        "\n",
        "question_schema = ResponseSchema(\n",
        "    name=\"question\",\n",
        "    description=\"a question about the context.\"\n",
        ")\n",
        "\n",
        "question_response_schemas = [\n",
        "    question_schema,\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebbmazGrdPap"
      },
      "outputs": [],
      "source": [
        "question_output_parser = StructuredOutputParser.from_response_schemas(question_response_schemas)\n",
        "format_instructions = question_output_parser.get_format_instructions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qorL4TPGXJQ7"
      },
      "outputs": [],
      "source": [
        "question_generation_llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
        "\n",
        "bare_prompt_template = \"{content}\"\n",
        "bare_template = ChatPromptTemplate.from_template(template=bare_prompt_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPqC1_MXdRuh"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "qa_template = \"\"\"\\\n",
        "You are a University Professor creating a test for advanced students. For each context, create a question that is specific to the context. Avoid creating generic or general questions.\n",
        "\n",
        "question: a question about the context.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "question\n",
        "\n",
        "context: {context}\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(template=qa_template)\n",
        "\n",
        "messages = prompt_template.format_messages(\n",
        "    context=docs[0],\n",
        "    format_instructions=format_instructions\n",
        ")\n",
        "\n",
        "question_generation_chain = bare_template | question_generation_llm\n",
        "\n",
        "response = question_generation_chain.invoke({\"content\" : messages})\n",
        "output_dict = question_output_parser.parse(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKFw9kyZd7eB",
        "outputId": "bbcf9e15-58be-4899-f102-6cae59c45eb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "question\n",
            "What is the aim of the paper 'A Survey on Retrieval-Augmented Text Generation'?\n"
          ]
        }
      ],
      "source": [
        "for k, v in output_dict.items():\n",
        "  print(k)\n",
        "  print(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtASDdhLfd89"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zolpr3CYeEYm",
        "outputId": "a7962cf2-4cdf-4c7a-b776-a0c2478042e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:35<00:00,  3.55s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "qac_triples = []\n",
        "\n",
        "for text in tqdm(docs[:10]):\n",
        "  messages = prompt_template.format_messages(\n",
        "      context=text,\n",
        "      format_instructions=format_instructions\n",
        "  )\n",
        "  response = question_generation_chain.invoke({\"content\" : messages})\n",
        "  try:\n",
        "    output_dict = question_output_parser.parse(response.content)\n",
        "  except Exception as e:\n",
        "    continue\n",
        "  output_dict[\"context\"] = text\n",
        "  qac_triples.append(output_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKBdQHK7Y2Vw",
        "outputId": "73c7d139-be2d-483f-9f70-b6c4aae91506"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'What is the main focus of this paper?',\n",
              " 'context': Document(page_content='thisisjcykcd@gmail.com, brandenwang@tencent.com\\nlemaoliu@gmail.com\\nAbstract\\nRecently, retrieval-augmented text generation\\nattracted increasing attention of the compu-\\ntational linguistics community.\\nCompared', metadata={'Published': '2022-02-13', 'Title': 'A Survey on Retrieval-Augmented Text Generation', 'Authors': 'Huayang Li, Yixuan Su, Deng Cai, Yan Wang, Lemao Liu', 'Summary': 'Recently, retrieval-augmented text generation attracted increasing attention\\nof the computational linguistics community. Compared with conventional\\ngeneration models, retrieval-augmented text generation has remarkable\\nadvantages and particularly has achieved state-of-the-art performance in many\\nNLP tasks. This paper aims to conduct a survey about retrieval-augmented text\\ngeneration. It firstly highlights the generic paradigm of retrieval-augmented\\ngeneration, and then it reviews notable approaches according to different tasks\\nincluding dialogue response generation, machine translation, and other\\ngeneration tasks. Finally, it points out some important directions on top of\\nrecent methods to facilitate future research.'})}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qac_triples[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNB9Z2DrX2TC"
      },
      "outputs": [],
      "source": [
        "answer_generation_llm = ChatOpenAI(model=\"gpt-4-1106-preview\", temperature=0)\n",
        "\n",
        "answer_schema = ResponseSchema(\n",
        "    name=\"answer\",\n",
        "    description=\"an answer to the question\"\n",
        ")\n",
        "\n",
        "answer_response_schemas = [\n",
        "    answer_schema,\n",
        "]\n",
        "\n",
        "answer_output_parser = StructuredOutputParser.from_response_schemas(answer_response_schemas)\n",
        "format_instructions = answer_output_parser.get_format_instructions()\n",
        "\n",
        "qa_template = \"\"\"\\\n",
        "You are a University Professor creating a test for advanced students. For each question and context, create an answer.\n",
        "\n",
        "answer: a answer about the context.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "answer\n",
        "\n",
        "question: {question}\n",
        "context: {context}\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(template=qa_template)\n",
        "\n",
        "messages = prompt_template.format_messages(\n",
        "    context=qac_triples[0][\"context\"],\n",
        "    question=qac_triples[0][\"question\"],\n",
        "    format_instructions=format_instructions\n",
        ")\n",
        "\n",
        "answer_generation_chain = bare_template | answer_generation_llm\n",
        "\n",
        "response = answer_generation_chain.invoke({\"content\" : messages})\n",
        "output_dict = answer_output_parser.parse(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk-_lRR6fn5U",
        "outputId": "fb014a65-a56f-49be-8ecf-9ca5527aa803"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "answer\n",
            "The focus of this paper is on retrieval-augmented text generation, which has gained increasing attention in the computational linguistics community. The paper conducts a survey of this field, highlighting the generic paradigm of retrieval-augmented generation, reviewing notable approaches across various tasks such as dialogue response generation and machine translation, and discussing future research directions.\n",
            "question\n",
            "What is the focus of the paper titled 'A Survey on Retrieval-Augmented Text Generation'?\n"
          ]
        }
      ],
      "source": [
        "for k, v in output_dict.items():\n",
        "  print(k)\n",
        "  print(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCdH0e9rrAKd",
        "outputId": "629d8791-dedb-47c7-b5a0-adaa26f142cd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [01:10<00:00,  7.09s/it]\n"
          ]
        }
      ],
      "source": [
        "for triple in tqdm(qac_triples):\n",
        "  messages = prompt_template.format_messages(\n",
        "      context=triple[\"context\"],\n",
        "      question=triple[\"question\"],\n",
        "      format_instructions=format_instructions\n",
        "  )\n",
        "  response = answer_generation_chain.invoke({\"content\" : messages})\n",
        "  try:\n",
        "    output_dict = answer_output_parser.parse(response.content)\n",
        "  except Exception as e:\n",
        "    continue\n",
        "  triple[\"answer\"] = output_dict[\"answer\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrHXgH9Qs1ep"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAvGGTyXsoHQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "ground_truth_qac_set = pd.DataFrame(qac_triples)\n",
        "ground_truth_qac_set[\"context\"] = ground_truth_qac_set[\"context\"].map(lambda x: str(x.page_content))\n",
        "ground_truth_qac_set = ground_truth_qac_set.rename(columns={\"answer\" : \"ground_truth\"})\n",
        "\n",
        "\n",
        "eval_dataset = Dataset.from_pandas(ground_truth_qac_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_FHUnAPVseB",
        "outputId": "1a907389-e62b-4686-b3d7-e8707acfbd47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['question', 'context', 'ground_truth'],\n",
              "    num_rows: 10\n",
              "})"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8CaCUeBVu4l",
        "outputId": "72cbf3c8-c698-4682-821a-8566f36f6adb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'What is the focus of this paper?',\n",
              " 'context': 'A Survey on Retrieval-Augmented Text Generation\\nHuayang Li♥,∗\\nYixuan Su♠,∗\\nDeng Cai♦,∗\\nYan Wang♣,∗\\nLemao Liu♣,∗\\n♥Nara Institute of Science and Technology\\n♠University of Cambridge\\n♦The Chinese University of Hong Kong\\n♣Tencent AI Lab',\n",
              " 'ground_truth': 'The focus of this paper is on retrieval-augmented text generation, which has gained increasing attention in the computational linguistics community. The paper surveys the paradigm of retrieval-augmented generation, reviews notable approaches across various NLP tasks such as dialogue response generation and machine translation, and discusses future research directions in this area.'}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "c4bc64d47f2e4a239cf7156e7812887d",
            "b4a71cf676584200b46922fb976d1d50",
            "65f75f3d72cd415faffb32999893738d",
            "5367cbe7ca4d43b089ff0d5d7cd17d3c",
            "31390facfbeb455fa83067fc23d30718",
            "22fc25617c664e4aa02b7457832c1bef",
            "b556054df18d47aa8cb58ac482ca31bb",
            "0fff4a6672c848a38945e19101c46168",
            "de662cb67d054f08a15d191923d40369",
            "b53ebcf672a244978391cae559db5bf2",
            "f2de6a2c1f4b4a2fa5196028c0da0754"
          ]
        },
        "id": "Nhp5X4M8zqrm",
        "outputId": "7e3c36df-12a3-4ea7-a772-dc1e0bc61568"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4bc64d47f2e4a239cf7156e7812887d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "7359"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_dataset.to_csv(\"groundtruth_eval_dataset.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Al5cagr-rvL"
      },
      "source": [
        "### Evaluating RAG Pipelines\n",
        "\n",
        "If you skipped ahead and need to load the `.csv` directly - uncomment the code below.\n",
        "\n",
        "If you're using Colab to do this notebook - please ensure you add it to your session files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "QJhes58R66-P"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "eval_dataset = Dataset.from_csv(\"groundtruth_eval_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fAD8c_kthWc",
        "outputId": "e722498d-3179-4cf1-e206-29a27163ace5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['question', 'context', 'ground_truth'],\n",
              "    num_rows: 10\n",
              "})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqFYbjLK-6X7"
      },
      "source": [
        "### Evaluation Using RAGAS\n",
        "\n",
        "Now we can evaluate using RAGAS!\n",
        "\n",
        "The set-up is fairly straightforward - we simply need to create a dataset with our generated answers and our contexts, and then evaluate using the framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1eBoHaf5t4w8"
      },
      "outputs": [],
      "source": [
        "from ragas.metrics import (\n",
        "    answer_relevancy,\n",
        "    faithfulness,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        "    answer_correctness,\n",
        "    answer_similarity\n",
        ")\n",
        "\n",
        "from ragas.metrics.critique import harmfulness\n",
        "from ragas import evaluate\n",
        "\n",
        "def create_ragas_dataset(rag_pipeline, eval_dataset):\n",
        "  rag_dataset = []\n",
        "  for row in tqdm(eval_dataset):\n",
        "    answer = rag_pipeline.invoke({\"question\" : row[\"question\"]})\n",
        "    rag_dataset.append(\n",
        "        {\"question\" : row[\"question\"],\n",
        "         \"answer\" : answer[\"response\"].content,\n",
        "         \"contexts\" : [context.page_content for context in answer[\"context\"]],\n",
        "         \"ground_truths\" : [row[\"ground_truth\"]]\n",
        "         }\n",
        "    )\n",
        "  rag_df = pd.DataFrame(rag_dataset)\n",
        "  rag_eval_dataset = Dataset.from_pandas(rag_df)\n",
        "  return rag_eval_dataset\n",
        "\n",
        "def evaluate_ragas_dataset(ragas_dataset):\n",
        "  result = evaluate(\n",
        "    ragas_dataset,\n",
        "    metrics=[\n",
        "        context_precision,\n",
        "        faithfulness,\n",
        "        answer_relevancy,\n",
        "        context_recall,\n",
        "        answer_correctness,\n",
        "        answer_similarity\n",
        "    ],\n",
        "  )\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4c4Jd8G_lXY"
      },
      "source": [
        "Lets create our dataset first:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7oXgcjkuopO",
        "outputId": "6db1a904-90a2-4e47-85da-a442ebdc56b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [23:29<00:00, 140.94s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "basic_qa_ragas_dataset = create_ragas_dataset(retrieval_augmented_qa_chain, eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfzaFWEMZ5l_",
        "outputId": "60ca3e05-209a-4375-f24c-a23ad06e525e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['question', 'answer', 'contexts', 'ground_truths'],\n",
              "    num_rows: 10\n",
              "})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basic_qa_ragas_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Vv1NsRGZ6m5",
        "outputId": "2ef4fbd9-011e-42b7-88d9-11c79974d87e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'What items were packed by Miep for Anne and her family, and what was the significance of these items in the context of their situation?',\n",
              " 'answer': ' **\"Miep arrived and promised to return later that night, taking with her a bag full of shoes, dresses, jackets, underwear and stockings.\"**\\n\\nAccording to the diary entry, Miep packed a bag for Anne and her family containing various essential items such as:\\n\\n* Shoes\\n* Dresses\\n* Jackets\\n* Underwear\\n* Stockings\\n\\nThese items were significant in the context of their situation because they represented a way for the family to take more clothes with them without arousing suspicion. As Anne mentions, \"No Jew in our situation would dare leave the house with a suitcase full of clothes.\" By packing these essential items, Miep helped the family to prepare for their hiding place while maintaining a sense of normalcy and avoiding drawing attention to themselves.\\n\\nThe packed bag also served as a way to maintain some semblance of normal life amidst the chaos and uncertainty of their situation. The diary entry highlights the importance of these small details in the face of adversity, demonstrating how even seemingly insignificant items can hold great significance in times of crisis.',\n",
              " 'contexts': ['be Petervan Daan’s bedroom. Then, just as in the front part of the building,\\nthere’s an attic and a loft. So there you are. Now I’ve introduced you to the\\nwhole of our lovely Annex!\\nYours, Anne\\nFriday, July 10, 1942\\nDearest Kitty,\\nI’ve probably bored you with my long description of our house, but I still think\\nyou should know where I’ve ended up; how I ended up here is something you’ll\\nfigure out from my next letters. But first, let me continue my story, because, as you\\nknow, I wasn’t finished.\\nAfter we arrived at 263 Prinsengracht, Miep quickly led us through the long\\nhallway and up the wooden staircase to the next floor and into the Annex. She shut\\nthe door behind us, leaving us alone. Margot had arrived much earlier on her bike\\nand was waiting for us.\\nOur living room and all the other rooms were so full of stuff that I can’t find the\\nwords to describe it. All the cardboard boxes that had been sent to the office in the\\nlast few months were piled on the floors and beds. The small room was filled from\\nfloor to ceiling with linens. If we wanted to sleep in properly made beds that night,\\nwe had to get going and straighten up the mess. Mother and Margot were unable to\\nmove a muscle. They lay down on their bare mattresses, tired, miserable and I don’t\\nknow what else. But Father and I, the two cleaner-uppers in the family, started in\\nright away.\\nAll day long we unpacked boxes, filled cupboards, hammered nails and\\nstraightened up the mess, until we fell exhausted into our clean beds at night. We\\n22',\n",
              "  'Miep arrived and promised to return later that night, taking with her a bag full of\\nshoes, dresses, jackets, underwear and stockings. After that it was quiet in our\\napartment; none of us felt like eating. It was still hot, and everything was very\\nstrange.\\nWe had rented our big upstairs room to a Mr. Goldschmidt, a divorced man\\nin his thirties, who apparently had nothing to do that evening, since despite all our\\npolite hints he hung around until ten o’clock. Miep and Jan Gies came at eleven.\\nMiep, who’s worked for Father’s company since1933, has become a close friend,\\nand so has her husband Jan. Once again, shoes, stockings, books and underwear\\ndisappeared into Miep’s bag and Jan’s deep pockets. Ateleven-thirty they too\\ndisappeared.\\nI was exhausted, and even though I knew it’d be my last night in my own bed,\\nI fell a sleep right away and didn’t wake up until Mother called me at five-thirty\\nthe next morning. Fortunately, it wasn’t as hot as Sunday; a warm rain fell\\nthroughout the day.\\nThe four of us were wrapped in so many layers of clothes it looked as if we\\nwere going off to spend the night in a refrigerator, and all that just so we could\\ntake more clothes with us. No Jew in our situation would dare leave the house\\nwith a suitcase full of clothes. I was wearing two undershirts, three pairs of\\nunderpants, a dress, and over that a skirt, a jacket, a raincoat, two pairs of\\nstockings, heavy shoes, a cap, a scarf and lots more. I was suffocating even before\\nwe left the house, but no one bothered to ask me how I felt.\\nMargot stuffed her school bag with schoolbooks, went to get her bicycle and,\\nwith Miep leading the way, rode off into the great unknown. At any rate, that’s\\nhow I thought of it, since I still didn’t know where our hiding place was.\\nAt seven-thirty we too closed the door behind us; Moortje, my cat, was the\\nonly living creature I said good-bye to. According to a note we left for Mr.\\nGoldschmidt, she was to be taken to the neighbors, who would give her a good',\n",
              "  'with Miep leading the way, rode off into the great unknown. At any rate, that’s\\nhow I thought of it, since I still didn’t know where our hiding place was.\\nAt seven-thirty we too closed the door behind us; Moortje, my cat, was the\\nonly living creature I said good-bye to. According to a note we left for Mr.\\nGoldschmidt, she was to be taken to the neighbors, who would give her a good\\nhome.\\nThe stripped beds, the breakfast things on the table, the pound of meat for the\\ncat in the kitchen — all of these created the impression that we’d left in a hurry.\\nBut we weren’t interested in impressions. We just wanted to get out of there, to get\\naway and reach our destination in safety. Nothing else mattered.\\nMore tomorrow.\\nYours, Anne\\n19',\n",
              "  'counts.\\nSome of our clothing was left with friends, but unfortunately we won’t be able\\nto get to it until after the war. Provided it’s still there, of course.\\nI’d just finished writing something about Mrs. van Daan when she walked\\ninto the room. Thump, I slammed the book shut.\\n“Hey, Anne, can’t I even take a peek?”\\n“No, Mrs. van Daan.”\\n“Just the last page then?”\\n“No, not even the last page, Mrs. van Daan.”\\nOf course, I nearly died, since that particular page contained a rather\\nunflattering description of her.\\nThere’s something happening every day, but I’m too tired and lazy to write\\nit all down.\\nYours, Anne\\n31'],\n",
              " 'ground_truths': [\"Miep packed shoes, dresses, jackets, underwear, and stockings for Anne and her family. The significance of these items lies in their necessity for the family's survival while in hiding. Given the context of their situation, where Jews were not allowed to carry luggage without raising suspicion, these items were essential for maintaining a semblance of normal life in their secret annex. The clothing allowed them to have a change of clothes without the risk of being seen carrying suitcases, which could lead to their discovery and arrest. The act of packing these items discreetly also helped to create the illusion that the family had left in a hurry, further protecting them from Nazi scrutiny.\"]}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basic_qa_ragas_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Obbgw3im_n01"
      },
      "source": [
        "Save it for later:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "86761a36bdb04fed9f1dae6e74da54ce",
            "e079c0eb3d9c4ae3a40491f059a864f7",
            "d4bde97f3895450782030cad7808ea59",
            "1d17b8847ab34a1d8fc79430e8b64a12",
            "fb953d8d116e4cc389dbc23a0055873f",
            "bf27f78edb15477492fb2d5dd8dc5137",
            "ee96a569b8a54944bcac1b1bc164e53e",
            "e556e254882340168833ecf1a7153a90",
            "c077837b8b044c2fb14dcd8fbc44a37b",
            "e5c8b5933c754a1192456f43682276c5",
            "84abf77081a04bb686f794b49e04761d"
          ]
        },
        "id": "6FG8x4i3yZ2B",
        "outputId": "52eb909f-69be-4c80-d9bc-77c2842bf14d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 115.31ba/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "74259"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basic_qa_ragas_dataset.to_csv(\"uniquery_ragas_dataset.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5I_d_RT_pFr"
      },
      "source": [
        "And finally - evaluate how it did!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywp3Rwavy9pc",
        "outputId": "7a3948ce-b743-4d95-a581-17e035215f3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:ragas.validation:passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
            "Evaluating:   7%|▋         | 4/60 [00:10<02:11,  2.34s/it]WARNING:ragas.metrics._faithfulness:No statements were generated from the answer.\n",
            "WARNING:ragas.metrics._faithfulness:No statements were generated from the answer.\n",
            "Evaluating:  20%|██        | 12/60 [00:12<00:35,  1.36it/s]WARNING:ragas.metrics._faithfulness:No statements were generated from the answer.\n",
            "Evaluating:  35%|███▌      | 21/60 [00:17<00:19,  1.99it/s]WARNING:ragas.metrics._faithfulness:No statements were generated from the answer.\n",
            "Evaluating:  43%|████▎     | 26/60 [00:20<00:20,  1.69it/s]WARNING:ragas.metrics._faithfulness:No statements were generated from the answer.\n",
            "Evaluating:  57%|█████▋    | 34/60 [00:23<00:14,  1.85it/s]WARNING:ragas.metrics._faithfulness:No statements were generated from the answer.\n",
            "Evaluating:  72%|███████▏  | 43/60 [00:27<00:08,  2.02it/s]WARNING:ragas.metrics._faithfulness:No statements were generated from the answer.\n",
            "Evaluating:  80%|████████  | 48/60 [00:28<00:04,  2.88it/s]WARNING:ragas.metrics._faithfulness:No statements were generated from the answer.\n",
            "Evaluating: 100%|██████████| 60/60 [00:44<00:00,  1.35it/s]\n"
          ]
        }
      ],
      "source": [
        "basic_qa_result = evaluate_ragas_dataset(basic_qa_ragas_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4oYnKTn15gY",
        "outputId": "ba48e4d2-5559-4748-8bc6-0101074a5c0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_precision': 1.0000, 'faithfulness': 0.3000, 'answer_relevancy': 0.3496, 'context_recall': 0.9333, 'answer_correctness': 0.2736, 'answer_similarity': 0.7441}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basic_qa_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwhBxlxYAdno"
      },
      "source": [
        "### Testing Other Retrievers\n",
        "\n",
        "Now we can test our how changing our Retriever impacts our RAGAS evaluation!\n",
        "\n",
        "We'll build this simple qa_chain factory to create standardized qa_chains where the only different component will be the retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnfy4VNkzZi2"
      },
      "outputs": [],
      "source": [
        "def create_qa_chain(retriever):\n",
        "  primary_qa_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "  created_qa_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | retriever,\n",
        "     \"question\": itemgetter(\"question\")\n",
        "    }\n",
        "    | RunnablePassthrough.assign(\n",
        "        context=itemgetter(\"context\")\n",
        "      )\n",
        "    | {\n",
        "         \"response\": prompt | primary_qa_llm,\n",
        "         \"context\": itemgetter(\"context\"),\n",
        "      }\n",
        "  )\n",
        "\n",
        "  return created_qa_chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOPp4Xq7AvEx"
      },
      "source": [
        "#### Parent Document Retriever\n",
        "\n",
        "One of the easier ways we can imagine improving a retriever is to embed our documents into small chunks, and then retrieve a significant amount of additional context that \"surrounds\" the found context.\n",
        "\n",
        "You can read more about this method [here](https://python.langchain.com/docs/modules/data_connection/retrievers/parent_document_retriever)!\n",
        "\n",
        "The basic outline of this retrieval method is as follows:\n",
        "\n",
        "1. Obtain User Question\n",
        "2. Retrieve child documents using Dense Vector Retrieval\n",
        "3. Merge the child documents based on their parents. If they have the same parents - they become merged.\n",
        "4. Replace the child documents with their respective parent documents from an in-memory-store.\n",
        "5. Use the parent documents to augment generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67I6QJAJ0Un7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/asura/miniconda3/envs/qdoc/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "Could not import chromadb python package. Please install it with `pip install chromadb`.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[0;32m~/miniconda3/envs/qdoc/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:82\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chromadb'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[55], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m parent_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1500\u001b[39m)\n\u001b[1;32m      5\u001b[0m child_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msplit_parents\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m store \u001b[38;5;241m=\u001b[39m InMemoryStore()\n",
            "File \u001b[0;32m~/miniconda3/envs/qdoc/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:85\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import chromadb python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install chromadb`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m     )\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_settings \u001b[38;5;241m=\u001b[39m client_settings\n",
            "\u001b[0;31mImportError\u001b[0m: Could not import chromadb python package. Please install it with `pip install chromadb`."
          ]
        }
      ],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "\n",
        "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=1500)\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)\n",
        "\n",
        "vectorstore = Chroma(collection_name=\"split_parents\", embedding_function=OpenAIEmbeddings())\n",
        "\n",
        "store = InMemoryStore()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfk5RYUt00Pw"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        "    parent_splitter=parent_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68c1t4o104AK"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(base_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTH0MDolBndm"
      },
      "source": [
        "Let's create, test, and then evaluate our new chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMjLfqOC09Iw"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever_qa_chain = create_qa_chain(parent_document_retriever)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Rv8bAHPN1H4P",
        "outputId": "faa6bf43-1604-4468-9faf-bbefd8e48281"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'RAG stands for Retrieval-Augmented Generation.'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retriever_qa_chain.invoke({\"question\" : \"What is RAG?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQJRIQmU1WTw",
        "outputId": "295a9011-684d-4c38-e409-867022603608"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:17<00:00,  1.80s/it]\n"
          ]
        }
      ],
      "source": [
        "pdr_qa_ragas_dataset = create_ragas_dataset(parent_document_retriever_qa_chain, eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "bf7f045bdbe24360ad2aa2f4c8f02e79",
            "761e3c6035bf49429b3035145451d2df",
            "ffb7c97e7af648aaa13a43427154140e",
            "95d92c5c74e845779337eb727c2bbfc0",
            "6e7fb9a1d1454fcd9bcf5b5f748fb975",
            "207785da1f404d6ea0e8c63655a7aa51",
            "71237d176b2c4138a5e0346d10482257",
            "ed457547dc154f6bbce4ec970bb09c76",
            "c9f479f81119450bb451d5830361467c",
            "56098a347ea94ea3b10bd8d2ec0d4288",
            "7940d9e3f5fa4592b58dec3fdb55595a"
          ]
        },
        "id": "d9vfKnCL1jtB",
        "outputId": "1d7421a8-b564-4da3-cd74-d1eb3f8311f7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf7f045bdbe24360ad2aa2f4c8f02e79",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "55620"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdr_qa_ragas_dataset.to_csv(\"pdr_qa_ragas_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfB1H9S_1mW3",
        "outputId": "426d7b1b-2b0c-40d3-e7d7-39da43363f06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating with [context_precision]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [01:01<00:00, 61.80s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating with [faithfulness]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [01:09<00:00, 69.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating with [answer_relevancy]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [01:04<00:00, 64.76s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating with [context_recall]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:06<00:00,  6.54s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating with [context_relevancy]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:04<00:00,  4.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating with [answer_correctness]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:06<00:00,  6.83s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating with [answer_similarity]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n"
          ]
        }
      ],
      "source": [
        "pdr_qa_result = evaluate_ragas_dataset(pdr_qa_ragas_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nFyYCdL2Nco",
        "outputId": "bdde7173-c649-40bc-cbc3-e38a70c9f50a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_precision': 0.6972, 'faithfulness': 0.3500, 'answer_relevancy': 0.9439, 'context_recall': 1.0000, 'context_relevancy': 0.0134, 'answer_correctness': 0.6000, 'answer_similarity': 1.0000}"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdr_qa_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaNk6o7_BqX8"
      },
      "source": [
        "#### Ensemble Retrieval\n",
        "\n",
        "Next let's look at ensemble retrieval!\n",
        "\n",
        "You can read more about this [here](https://python.langchain.com/docs/modules/data_connection/retrievers/ensemble)!\n",
        "\n",
        "The basic idea is as follows:\n",
        "\n",
        "1. Obtain User Question\n",
        "2. Hit the Retriever Pair\n",
        "    - Retrieve Documents with BM25 Sparse Vector Retrieval\n",
        "    - Retrieve Documents with Dense Vector Retrieval Method\n",
        "3. Collect and \"fuse\" the retrieved docs based on their weighting using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm into a single ranked list.\n",
        "4. Use those documents to augment our generation.\n",
        "\n",
        "Ensure your `weights` list - the relative weighting of each retriever - sums to 1!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zz7dl1GD5-L-"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U rank_bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vs8wxT9b5pRA"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=450, chunk_overlap=75)\n",
        "docs = text_splitter.split_documents(base_docs)\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(docs)\n",
        "bm25_retriever.k = 2\n",
        "\n",
        "embedding = OpenAIEmbeddings()\n",
        "vectorstore = Chroma.from_documents(docs, embedding)\n",
        "chroma_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, chroma_retriever], weights=[0.75, 0.25])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cv69YDpF6PrJ"
      },
      "outputs": [],
      "source": [
        "ensemble_retriever_qa_chain = create_qa_chain(ensemble_retriever)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6lSszzrf6UmP",
        "outputId": "8a5893d5-4095-42e5-aecf-66d849512321"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'RAG stands for Retrieval-Augmented Generation.'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retriever_qa_chain.invoke({\"question\" : \"What is RAG?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abUgTGDT6UrV",
        "outputId": "749ae6db-75b9-48a7-e743-a8aecdcbd802"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:20<00:00,  2.07s/it]\n"
          ]
        }
      ],
      "source": [
        "ensemble_qa_ragas_dataset = create_ragas_dataset(ensemble_retriever_qa_chain, eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "632135599e39470aac1a3bb3d3de0ca4",
            "567176b50d074a1c9d384a8df8c3ff4c",
            "6bfa39f2c84e4f08b5ffb9a416398824",
            "911b40169865413b98643789150e5495",
            "2add9d30edd84152bb6d7bfa4ed2d910",
            "f34ffd11b98045b9bae326dd48a54896",
            "e3e19fc9963c4bf39293bda7c2030d5a",
            "c15c27b0523a429e9d77f439d47ada90",
            "256a0dbb2f104d928e181d2a882a9867",
            "68790cfe4ea14fc4a63275f3e99c468f",
            "e7df092ac205443e8baa3646ff1eae5b"
          ]
        },
        "id": "bGHipYsf7phk",
        "outputId": "a70b0d3e-870f-49b8-a16a-5b7d4623c33f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "632135599e39470aac1a3bb3d3de0ca4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "22820"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_qa_ragas_dataset.to_csv(\"ensemble_qa_ragas_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ozo0jkvx7r1d",
        "outputId": "f5770c52-4614-4172-8834-d48bd4005218"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating with [context_precision]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [01:01<00:00, 61.76s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating with [faithfulness]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [01:08<00:00, 68.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating with [answer_relevancy]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:05<00:00,  5.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating with [context_recall]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:11<00:00, 11.67s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating with [context_relevancy]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [01:02<00:00, 62.45s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating with [answer_correctness]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:08<00:00,  9.00s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating with [answer_similarity]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n"
          ]
        }
      ],
      "source": [
        "ensemble_qa_result = evaluate_ragas_dataset(ensemble_qa_ragas_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvabdcbh793a",
        "outputId": "56daa44b-841b-4924-9242-77c2bc93f86e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_precision': 0.8858, 'faithfulness': 0.7000, 'answer_relevancy': 0.8918, 'context_recall': 0.9800, 'context_relevancy': 0.0192, 'answer_correctness': 0.7750, 'answer_similarity': 1.0000}"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_qa_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4vXVWqiCcSI"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "Observe your results in a table!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmBoVQ5hV3Kc",
        "outputId": "12196187-5cbf-40b2-f35f-ab45616e71a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_precision': 0.5000, 'faithfulness': 0.4000, 'answer_relevancy': 0.9535, 'context_recall': 1.0000, 'context_relevancy': 0.0559, 'answer_correctness': 0.6167, 'answer_similarity': 1.0000}"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basic_qa_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax1JLXKxUsXF",
        "outputId": "b83ba792-7e66-44ff-b219-0f3890a5fe8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_precision': 0.6972, 'faithfulness': 0.3500, 'answer_relevancy': 0.9439, 'context_recall': 1.0000, 'context_relevancy': 0.0134, 'answer_correctness': 0.6000, 'answer_similarity': 1.0000}"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdr_qa_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drxLlO3zUpyQ",
        "outputId": "3b595607-2fa5-4590-d2e6-9707aa7bb283"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_precision': 0.8858, 'faithfulness': 0.7000, 'answer_relevancy': 0.8918, 'context_recall': 0.9800, 'context_relevancy': 0.0192, 'answer_correctness': 0.7750, 'answer_similarity': 1.0000}"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_qa_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6YPGf-2l0Kx"
      },
      "source": [
        "We can also zoom in on each result and find specific information about each of the questions and answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkxLtk43ikka"
      },
      "outputs": [],
      "source": [
        "ensemble_qa_result_df = ensemble_qa_result.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3JZMhUg3jSvE",
        "outputId": "95d1cf44-88ee-4056-b698-64237b119fe0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a1e0be28-2fa7-4b13-8d13-5b1c1554cdd9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>contexts</th>\n",
              "      <th>answer</th>\n",
              "      <th>ground_truths</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_relevancy</th>\n",
              "      <th>answer_correctness</th>\n",
              "      <th>answer_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the focus of this paper?</td>\n",
              "      <td>[has to make an important career decision.\\nNe...</td>\n",
              "      <td>The focus of this paper is on a framework call...</td>\n",
              "      <td>[The focus of this paper is on retrieval-augme...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.784617</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.50</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the title of the paper?</td>\n",
              "      <td>[of War. The game was released worldwide in\\nG...</td>\n",
              "      <td>Title: Self-RAG: Learning to Retrieve, Generat...</td>\n",
              "      <td>[The title of the paper is 'A Survey on Retrie...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.976911</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.50</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the aim of this paper?</td>\n",
              "      <td>[has to make an important career decision.\\nNe...</td>\n",
              "      <td>The aim of this paper is to introduce a new fr...</td>\n",
              "      <td>[The aim of this paper is to conduct a compreh...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.800732</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.078947</td>\n",
              "      <td>0.75</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the main focus of the paper 'A Survey ...</td>\n",
              "      <td>[A Survey on Retrieval-Augmented Text Generati...</td>\n",
              "      <td>The main focus of the paper 'A Survey on Retri...</td>\n",
              "      <td>[The main focus of the paper 'A Survey on Retr...</td>\n",
              "      <td>0.679167</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.982435</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.017857</td>\n",
              "      <td>1.00</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the main focus of this paper?</td>\n",
              "      <td>[example of completions of the prompt by diffe...</td>\n",
              "      <td>I don't know.</td>\n",
              "      <td>[The main focus of this paper is to conduct a ...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.742601</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.50</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What is the main focus of this paper?</td>\n",
              "      <td>[example of completions of the prompt by diffe...</td>\n",
              "      <td>I don't know.</td>\n",
              "      <td>[The main focus of this paper is to conduct a ...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.742601</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.50</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What are the advantages of retrieval-augmented...</td>\n",
              "      <td>[attracted increasing attention of the compu-\\...</td>\n",
              "      <td>The advantages of retrieval-augmented text gen...</td>\n",
              "      <td>[The advantages of retrieval-augmented text ge...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.968712</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.025641</td>\n",
              "      <td>1.00</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What is the main focus of the paper 'A Survey ...</td>\n",
              "      <td>[A Survey on Retrieval-Augmented Text Generati...</td>\n",
              "      <td>The main focus of the paper 'A Survey on Retri...</td>\n",
              "      <td>[The main focus of the paper 'A Survey on Retr...</td>\n",
              "      <td>0.679167</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.982422</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.017857</td>\n",
              "      <td>1.00</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What are the advantages of retrieval-augmented...</td>\n",
              "      <td>[attracted increasing attention of the compu-\\...</td>\n",
              "      <td>The advantages of retrieval-augmented text gen...</td>\n",
              "      <td>[The advantages of retrieval-augmented text ge...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.968731</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.025641</td>\n",
              "      <td>1.00</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>What are the advantages of retrieval-augmented...</td>\n",
              "      <td>[attracted increasing attention of the compu-\\...</td>\n",
              "      <td>The advantages of retrieval-augmented text gen...</td>\n",
              "      <td>[The advantages of retrieval-augmented text ge...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.968692</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.025641</td>\n",
              "      <td>1.00</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1e0be28-2fa7-4b13-8d13-5b1c1554cdd9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a1e0be28-2fa7-4b13-8d13-5b1c1554cdd9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a1e0be28-2fa7-4b13-8d13-5b1c1554cdd9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9d17e429-a85f-4eed-ab52-253849a35ce1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9d17e429-a85f-4eed-ab52-253849a35ce1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9d17e429-a85f-4eed-ab52-253849a35ce1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0                   What is the focus of this paper?   \n",
              "1                    What is the title of the paper?   \n",
              "2                     What is the aim of this paper?   \n",
              "3  What is the main focus of the paper 'A Survey ...   \n",
              "4              What is the main focus of this paper?   \n",
              "5              What is the main focus of this paper?   \n",
              "6  What are the advantages of retrieval-augmented...   \n",
              "7  What is the main focus of the paper 'A Survey ...   \n",
              "8  What are the advantages of retrieval-augmented...   \n",
              "9  What are the advantages of retrieval-augmented...   \n",
              "\n",
              "                                            contexts  \\\n",
              "0  [has to make an important career decision.\\nNe...   \n",
              "1  [of War. The game was released worldwide in\\nG...   \n",
              "2  [has to make an important career decision.\\nNe...   \n",
              "3  [A Survey on Retrieval-Augmented Text Generati...   \n",
              "4  [example of completions of the prompt by diffe...   \n",
              "5  [example of completions of the prompt by diffe...   \n",
              "6  [attracted increasing attention of the compu-\\...   \n",
              "7  [A Survey on Retrieval-Augmented Text Generati...   \n",
              "8  [attracted increasing attention of the compu-\\...   \n",
              "9  [attracted increasing attention of the compu-\\...   \n",
              "\n",
              "                                              answer  \\\n",
              "0  The focus of this paper is on a framework call...   \n",
              "1  Title: Self-RAG: Learning to Retrieve, Generat...   \n",
              "2  The aim of this paper is to introduce a new fr...   \n",
              "3  The main focus of the paper 'A Survey on Retri...   \n",
              "4                                      I don't know.   \n",
              "5                                      I don't know.   \n",
              "6  The advantages of retrieval-augmented text gen...   \n",
              "7  The main focus of the paper 'A Survey on Retri...   \n",
              "8  The advantages of retrieval-augmented text gen...   \n",
              "9  The advantages of retrieval-augmented text gen...   \n",
              "\n",
              "                                       ground_truths  context_precision  \\\n",
              "0  [The focus of this paper is on retrieval-augme...           1.000000   \n",
              "1  [The title of the paper is 'A Survey on Retrie...           0.500000   \n",
              "2  [The aim of this paper is to conduct a compreh...           1.000000   \n",
              "3  [The main focus of the paper 'A Survey on Retr...           0.679167   \n",
              "4  [The main focus of this paper is to conduct a ...           1.000000   \n",
              "5  [The main focus of this paper is to conduct a ...           1.000000   \n",
              "6  [The advantages of retrieval-augmented text ge...           1.000000   \n",
              "7  [The main focus of the paper 'A Survey on Retr...           0.679167   \n",
              "8  [The advantages of retrieval-augmented text ge...           1.000000   \n",
              "9  [The advantages of retrieval-augmented text ge...           1.000000   \n",
              "\n",
              "   faithfulness  answer_relevancy  context_recall  context_relevancy  \\\n",
              "0      0.666667          0.784617             1.0           0.000000   \n",
              "1      1.000000          0.976911             1.0           0.000000   \n",
              "2      0.333333          0.800732             1.0           0.078947   \n",
              "3      1.000000          0.982435             0.8           0.017857   \n",
              "4      0.000000          0.742601             1.0           0.000000   \n",
              "5      0.000000          0.742601             1.0           0.000000   \n",
              "6      1.000000          0.968712             1.0           0.025641   \n",
              "7      1.000000          0.982422             1.0           0.017857   \n",
              "8      1.000000          0.968731             1.0           0.025641   \n",
              "9      1.000000          0.968692             1.0           0.025641   \n",
              "\n",
              "   answer_correctness  answer_similarity  \n",
              "0                0.50               True  \n",
              "1                0.50               True  \n",
              "2                0.75               True  \n",
              "3                1.00               True  \n",
              "4                0.50               True  \n",
              "5                0.50               True  \n",
              "6                1.00               True  \n",
              "7                1.00               True  \n",
              "8                1.00               True  \n",
              "9                1.00               True  "
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_qa_result_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jXR7ckel-v8"
      },
      "source": [
        "We'll also look at combining the results and looking at them in a single table so we can make inferences about them!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BE5KKE_JkcD3"
      },
      "outputs": [],
      "source": [
        "def create_df_dict(pipeline_name, pipeline_items):\n",
        "  df_dict = {\"name\" : pipeline_name}\n",
        "  for name, score in pipeline_items:\n",
        "    df_dict[name] = score\n",
        "  return df_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1mPqYdqk4iQ"
      },
      "outputs": [],
      "source": [
        "basic_rag_df_dict = create_df_dict(\"basic_rag\", basic_qa_result.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntJPzwy9lI46"
      },
      "outputs": [],
      "source": [
        "pdr_rag_df_dict = create_df_dict(\"pdr_rag\", pdr_qa_result.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0fkbIQElPza"
      },
      "outputs": [],
      "source": [
        "ensemble_rag_df_dict = create_df_dict(\"ensemble_rag\", ensemble_qa_result.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bc4T1E83lVbE"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame([basic_rag_df_dict, pdr_rag_df_dict, ensemble_rag_df_dict])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "cv_9wNYGlibg",
        "outputId": "6580c17c-543a-4d54-8577-104c0173f368"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b21809b4-1506-4413-b95a-a7bdc7cf6816\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_relevancy</th>\n",
              "      <th>answer_correctness</th>\n",
              "      <th>answer_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ensemble_rag</td>\n",
              "      <td>0.885833</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.891845</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.019158</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>basic_rag</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.953475</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.055904</td>\n",
              "      <td>0.616667</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pdr_rag</td>\n",
              "      <td>0.697222</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.943909</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.013386</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b21809b4-1506-4413-b95a-a7bdc7cf6816')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b21809b4-1506-4413-b95a-a7bdc7cf6816 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b21809b4-1506-4413-b95a-a7bdc7cf6816');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-43d2deee-1b4d-4900-9ce8-743ac419b9d1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-43d2deee-1b4d-4900-9ce8-743ac419b9d1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-43d2deee-1b4d-4900-9ce8-743ac419b9d1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           name  context_precision  faithfulness  answer_relevancy  \\\n",
              "2  ensemble_rag           0.885833          0.70          0.891845   \n",
              "0     basic_rag           0.500000          0.40          0.953475   \n",
              "1       pdr_rag           0.697222          0.35          0.943909   \n",
              "\n",
              "   context_recall  context_relevancy  answer_correctness  answer_similarity  \n",
              "2            0.98           0.019158            0.775000                1.0  \n",
              "0            1.00           0.055904            0.616667                1.0  \n",
              "1            1.00           0.013386            0.600000                1.0  "
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df.sort_values(\"answer_correctness\", ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPocfrNFiYWi"
      },
      "source": [
        "### ❓QUESTION❓\n",
        "\n",
        "What conclusions can you draw about the above results?\n",
        "\n",
        "Describe in your own words what the metrics are expressing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbhz-vD4JPtN"
      },
      "outputs": [],
      "source": [
        "retrieval_augmented_qa_chain = (\n",
        "    RunnableParallel({\n",
        "        'context': itemgetter('question') | base_retriever,\n",
        "        'question': RunnablePassthrough()\n",
        "    }) | {\n",
        "        'response': prompt | primary_qa_llm | parser,\n",
        "        'context': itemgetter('context')\n",
        "    }\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "undefined.undefined.undefined"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0fff4a6672c848a38945e19101c46168": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d17b8847ab34a1d8fc79430e8b64a12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5c8b5933c754a1192456f43682276c5",
            "placeholder": "​",
            "style": "IPY_MODEL_84abf77081a04bb686f794b49e04761d",
            "value": " 1/1 [00:00&lt;00:00, 35.79ba/s]"
          }
        },
        "207785da1f404d6ea0e8c63655a7aa51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22fc25617c664e4aa02b7457832c1bef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "256a0dbb2f104d928e181d2a882a9867": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2add9d30edd84152bb6d7bfa4ed2d910": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31390facfbeb455fa83067fc23d30718": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5367cbe7ca4d43b089ff0d5d7cd17d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b53ebcf672a244978391cae559db5bf2",
            "placeholder": "​",
            "style": "IPY_MODEL_f2de6a2c1f4b4a2fa5196028c0da0754",
            "value": " 1/1 [00:00&lt;00:00, 18.79ba/s]"
          }
        },
        "56098a347ea94ea3b10bd8d2ec0d4288": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "567176b50d074a1c9d384a8df8c3ff4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f34ffd11b98045b9bae326dd48a54896",
            "placeholder": "​",
            "style": "IPY_MODEL_e3e19fc9963c4bf39293bda7c2030d5a",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "632135599e39470aac1a3bb3d3de0ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_567176b50d074a1c9d384a8df8c3ff4c",
              "IPY_MODEL_6bfa39f2c84e4f08b5ffb9a416398824",
              "IPY_MODEL_911b40169865413b98643789150e5495"
            ],
            "layout": "IPY_MODEL_2add9d30edd84152bb6d7bfa4ed2d910"
          }
        },
        "65f75f3d72cd415faffb32999893738d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fff4a6672c848a38945e19101c46168",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de662cb67d054f08a15d191923d40369",
            "value": 1
          }
        },
        "68790cfe4ea14fc4a63275f3e99c468f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bfa39f2c84e4f08b5ffb9a416398824": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c15c27b0523a429e9d77f439d47ada90",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_256a0dbb2f104d928e181d2a882a9867",
            "value": 1
          }
        },
        "6e7fb9a1d1454fcd9bcf5b5f748fb975": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71237d176b2c4138a5e0346d10482257": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "761e3c6035bf49429b3035145451d2df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_207785da1f404d6ea0e8c63655a7aa51",
            "placeholder": "​",
            "style": "IPY_MODEL_71237d176b2c4138a5e0346d10482257",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "7940d9e3f5fa4592b58dec3fdb55595a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84abf77081a04bb686f794b49e04761d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86761a36bdb04fed9f1dae6e74da54ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e079c0eb3d9c4ae3a40491f059a864f7",
              "IPY_MODEL_d4bde97f3895450782030cad7808ea59",
              "IPY_MODEL_1d17b8847ab34a1d8fc79430e8b64a12"
            ],
            "layout": "IPY_MODEL_fb953d8d116e4cc389dbc23a0055873f"
          }
        },
        "911b40169865413b98643789150e5495": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68790cfe4ea14fc4a63275f3e99c468f",
            "placeholder": "​",
            "style": "IPY_MODEL_e7df092ac205443e8baa3646ff1eae5b",
            "value": " 1/1 [00:00&lt;00:00, 33.41ba/s]"
          }
        },
        "95d92c5c74e845779337eb727c2bbfc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56098a347ea94ea3b10bd8d2ec0d4288",
            "placeholder": "​",
            "style": "IPY_MODEL_7940d9e3f5fa4592b58dec3fdb55595a",
            "value": " 1/1 [00:00&lt;00:00, 33.86ba/s]"
          }
        },
        "b4a71cf676584200b46922fb976d1d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22fc25617c664e4aa02b7457832c1bef",
            "placeholder": "​",
            "style": "IPY_MODEL_b556054df18d47aa8cb58ac482ca31bb",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "b53ebcf672a244978391cae559db5bf2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b556054df18d47aa8cb58ac482ca31bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf27f78edb15477492fb2d5dd8dc5137": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf7f045bdbe24360ad2aa2f4c8f02e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_761e3c6035bf49429b3035145451d2df",
              "IPY_MODEL_ffb7c97e7af648aaa13a43427154140e",
              "IPY_MODEL_95d92c5c74e845779337eb727c2bbfc0"
            ],
            "layout": "IPY_MODEL_6e7fb9a1d1454fcd9bcf5b5f748fb975"
          }
        },
        "c077837b8b044c2fb14dcd8fbc44a37b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c15c27b0523a429e9d77f439d47ada90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4bc64d47f2e4a239cf7156e7812887d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4a71cf676584200b46922fb976d1d50",
              "IPY_MODEL_65f75f3d72cd415faffb32999893738d",
              "IPY_MODEL_5367cbe7ca4d43b089ff0d5d7cd17d3c"
            ],
            "layout": "IPY_MODEL_31390facfbeb455fa83067fc23d30718"
          }
        },
        "c9f479f81119450bb451d5830361467c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4bde97f3895450782030cad7808ea59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e556e254882340168833ecf1a7153a90",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c077837b8b044c2fb14dcd8fbc44a37b",
            "value": 1
          }
        },
        "de662cb67d054f08a15d191923d40369": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e079c0eb3d9c4ae3a40491f059a864f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf27f78edb15477492fb2d5dd8dc5137",
            "placeholder": "​",
            "style": "IPY_MODEL_ee96a569b8a54944bcac1b1bc164e53e",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "e3e19fc9963c4bf39293bda7c2030d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e556e254882340168833ecf1a7153a90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5c8b5933c754a1192456f43682276c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7df092ac205443e8baa3646ff1eae5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed457547dc154f6bbce4ec970bb09c76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee96a569b8a54944bcac1b1bc164e53e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2de6a2c1f4b4a2fa5196028c0da0754": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f34ffd11b98045b9bae326dd48a54896": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb953d8d116e4cc389dbc23a0055873f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffb7c97e7af648aaa13a43427154140e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed457547dc154f6bbce4ec970bb09c76",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9f479f81119450bb451d5830361467c",
            "value": 1
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
